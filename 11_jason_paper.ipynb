{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conic Solver Approach for Implied Returns\n",
    "\n",
    "This notebook reformulates the Nelder-Mead optimization approach from notebook 10 using cvxpy conic solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import cvxpy as cp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD INPUT PRICE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(sourcefile):\n",
    "    try:\n",
    "        source_df=pd.read_csv(sourcefile)\n",
    "        temp=source_df.get('Date')\n",
    "        if not temp is None:\n",
    "            source_df.index=temp \n",
    "            source_df=source_df.drop(columns=['Date'])\n",
    "        return source_df\n",
    "    except:\n",
    "        print('NO SOURCE FOUND')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "def implied_dif_returns_conic(rtns, lev, allocation, worst, target_exputil):\n    nrows, ncols = rtns.shape\n    \n    # Decision variable: adjustment to returns\n    x = cp.Variable(ncols)\n    \n    # Auxiliary variables for log terms\n    t = cp.Variable(nrows)\n    \n    # Calculate adjusted portfolio returns\n    # rtns is (nrows, ncols), x is (ncols,), allocation is (ncols,)\n    # We need to broadcast x to match rtns shape\n    adjusted_rtns = rtns + cp.reshape(x, (1, ncols))\n    port_rtns = adjusted_rtns @ allocation\n    lev_port_rtns = lev * port_rtns\n    \n    # Constraints\n    constraints = []\n    \n    # Ensure 1 + lev_port_rtns > 0 (needed for log1p)\n    constraints.append(1 + lev_port_rtns >= 1e-8)\n    \n    # Worst return constraint\n    constraints.append(lev_port_rtns >= worst)\n    \n    # Log constraint using exponential cone\n    # We want: t[i] <= log(1 + lev_port_rtns[i])\n    # This is equivalent to: exp(t[i]) <= 1 + lev_port_rtns[i]\n    for i in range(nrows):\n        # ExpCone requires all arguments to be expressions with same shape\n        one_expr = cp.Constant(1)\n        constraints.append(cp.constraints.ExpCone(t[i], one_expr, 1 + lev_port_rtns[i]))\n    \n    # Target expected utility constraint\n    # We want: sum(t) / nrows / lev = target_exputil\n    constraints.append(cp.sum(t) == target_exputil * nrows * lev)\n    \n    # Objective: minimize norm of adjustments\n    objective = cp.Minimize(cp.norm(x, 2))\n    \n    prob = cp.Problem(objective, constraints)\n    \n    try:\n        result = prob.solve(solver=cp.CLARABEL, verbose=False)\n        if x.value is None:\n            print(\"Warning: cvxpy problem appears not feasible.\")\n            # Fall back to Nelder-Mead\n            return implied_dif_returns_nelder(rtns, lev, allocation, worst, target_exputil)\n        return x.value\n    except Exception as e:\n        print(f\"Conic solver failed: {e}\")\n        # Fall back to Nelder-Mead\n        return implied_dif_returns_nelder(rtns, lev, allocation, worst, target_exputil)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(source_df):\n",
    "    price_data=np.array(source_df.values,dtype='float64')\n",
    "    price_data1=np.ones((price_data.shape[0],price_data.shape[1]))\n",
    "    price_data1[1:]=price_data[:-1]\n",
    "    returns=(price_data/price_data1)\n",
    "    returns=returns[1:]-1. \n",
    "    returns_df=pd.DataFrame(returns,columns=source_df.columns,index=source_df.index[1:])   \n",
    "    return(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIND BEST ALLOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_allocation(rtns_df,lev,long_only,worst):\n",
    "    rtns=rtns_df.values\n",
    "    nrows,ncols=rtns.shape\n",
    "    levreturn=(rtns*lev)\n",
    "    \n",
    "    xx=cp.Variable(ncols)\n",
    "    if long_only:\n",
    "        constraints =[sum(xx)==1, 0<=xx, xx<=1, worst <= levreturn @ xx ]\n",
    "    else:\n",
    "        constraints = [sum(xx)==1,worst <= levreturn @ xx ]\n",
    "    objective=cp.Minimize(cp.sum(-cp.log1p(levreturn @ xx)))\n",
    "    prob=cp.Problem(objective,constraints)\n",
    "    result=prob.solve(solver=cp.CLARABEL,tol_feas=1e-7,tol_gap_abs=1e-7, tol_gap_rel=1e-7, tol_ktratio=1e-7, verbose=False) /nrows/lev\n",
    "    xxvalue=xx.value #allocation\n",
    "            \n",
    "    if xxvalue is None:                \n",
    "        print('WARNING!!!! cvxpy problem mappears not feasible.')\n",
    "        return None\n",
    "                \n",
    "    prtns=np.dot(rtns,xxvalue)     \n",
    "    alloc=xxvalue \n",
    "\n",
    "    return ('dummy',prtns,xxvalue,-result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLIED RETURNS ESTIMATOR - CONIC SOLVER VERSION\n",
    "\n",
    "This reformulates the Nelder-Mead approach using cvxpy with conic constraints.\n",
    "The key insight is to introduce auxiliary variables to handle the log terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implied_dif_returns_conic(rtns, lev, allocation, worst, target_exputil):\n",
    "    nrows, ncols = rtns.shape\n",
    "    \n",
    "    # Decision variable: adjustment to returns\n",
    "    x = cp.Variable(ncols)\n",
    "    \n",
    "    # Auxiliary variables for log terms\n",
    "    t = cp.Variable(nrows)\n",
    "    \n",
    "    # Calculate adjusted portfolio returns\n",
    "    # rtns is (nrows, ncols), x is (ncols,), allocation is (ncols,)\n",
    "    # We need to broadcast x to match rtns shape\n",
    "    adjusted_rtns = rtns + cp.reshape(x, (1, ncols))\n",
    "    port_rtns = adjusted_rtns @ allocation\n",
    "    lev_port_rtns = lev * port_rtns\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = []\n",
    "    \n",
    "    # Ensure 1 + lev_port_rtns > 0 (needed for log1p)\n",
    "    constraints.append(1 + lev_port_rtns >= 1e-8)\n",
    "    \n",
    "    # Worst return constraint\n",
    "    constraints.append(lev_port_rtns >= worst)\n",
    "    \n",
    "    # Log constraint using exponential cone\n",
    "    # We want: t[i] <= log(1 + lev_port_rtns[i])\n",
    "    # This is equivalent to: exp(t[i]) <= 1 + lev_port_rtns[i]\n",
    "    for i in range(nrows):\n",
    "        constraints.append(cp.constraints.ExpCone(t[i], 1, 1 + lev_port_rtns[i]))\n",
    "    \n",
    "    # Target expected utility constraint\n",
    "    # We want: sum(t) / nrows / lev = target_exputil\n",
    "    constraints.append(cp.sum(t) == target_exputil * nrows * lev)\n",
    "    \n",
    "    # Objective: minimize norm of adjustments\n",
    "    objective = cp.Minimize(cp.norm(x, 2))\n",
    "    \n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    try:\n",
    "        result = prob.solve(solver=cp.CLARABEL, verbose=False)\n",
    "        if x.value is None:\n",
    "            print(\"Warning: cvxpy problem appears not feasible.\")\n",
    "            # Fall back to Nelder-Mead\n",
    "            return implied_dif_returns_nelder(rtns, lev, allocation, worst, target_exputil)\n",
    "        return x.value\n",
    "    except Exception as e:\n",
    "        print(f\"Conic solver failed: {e}\")\n",
    "        # Fall back to Nelder-Mead\n",
    "        return implied_dif_returns_nelder(rtns, lev, allocation, worst, target_exputil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLIED RETURNS ESTIMATOR - NELDER-MEAD (FALLBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implied_dif_returns_nelder(rtns, lev, allocation, worst, target_exputil):\n",
    "\n",
    "    nrows, ncols = rtns.shape\n",
    "    \n",
    "    def objective(x):\n",
    "        adjusted_rtns = rtns + x[np.newaxis, :]\n",
    "        port_rtns = adjusted_rtns @ allocation\n",
    "        lev_port_rtns = lev * port_rtns\n",
    "        \n",
    "        if np.any(1 + lev_port_rtns <= 0):\n",
    "            return 1e10\n",
    "        \n",
    "        exp_util = np.sum(np.log1p(lev_port_rtns)) / nrows / lev\n",
    "        return (exp_util - target_exputil)**2\n",
    "    \n",
    "    x0 = np.zeros(ncols)\n",
    "    result = minimize(objective, x0, method='Nelder-Mead', \n",
    "                     options={'xatol': 1e-8, 'fatol': 1e-12, 'maxiter': 20000})\n",
    "    \n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLIED EXPECTED RETURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_implied_dif_expected_returns(returns_df, lev, worst, walloc, exputil, use_conic=True):\n",
    "    rtns = returns_df.values\n",
    "    ncols=rtns.shape[1]\n",
    "    \n",
    "    #allocation = walloc  # This allocation seems likely to produce differential returns near zero,\n",
    "    #since it was the optimum given the same context.\n",
    "    allocation =(1./ncols) * np.ones((ncols,1))  #This one is of greater interest\n",
    "    \n",
    "    if use_conic:\n",
    "        output = implied_dif_returns_conic(rtns, lev, allocation, worst, exputil).T\n",
    "    else:\n",
    "        output = implied_dif_returns_nelder(rtns, lev, allocation, worst, exputil).T\n",
    "   \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRINT PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters(sourcefile,sourcetype,Llist,long_only,worst,actual_alloc,expected_returns):\n",
    "    print(' ')    \n",
    "    print(f'{sourcefile=}')\n",
    "    print(f'{sourcetype=}')\n",
    "    print(f'{Llist=}')\n",
    "    print(f'{long_only=}') \n",
    "    print(f'{worst=}')\n",
    "    print(f'{actual_alloc=}')\n",
    "    print(f'{expected_returns=}')\n",
    "    print(' ')\n",
    "    return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woptimize(params={}):\n",
    "\n",
    "    sourcefile=params.get('sourcefile')\n",
    "    sourcetype=params.get('sourcetype')    \n",
    "    Llist=params.get('Llist')\n",
    "    long_only=params.get('long_only')\n",
    "    worst=params.get('worst')\n",
    "    actual_alloc=params.get('actual_alloc')\n",
    "    expected_returns=params.get('expected_returns')\n",
    "    use_conic=params.get('use_conic', True)\n",
    "    \n",
    "    #record control parameters\n",
    "    print_parameters(sourcefile,sourcetype,Llist,long_only,worst,actual_alloc, expected_returns)\n",
    "        \n",
    "    #Read in Prices or Returns, based on sourcetype, adjusted for dividends and interest if possible\n",
    "    if sourcetype=='PRICES':        \n",
    "        #Calculate return matrix\n",
    "        returns_df=calculate_returns(load_source(sourcefile))\n",
    "    elif sourcetype=='RETURNS':\n",
    "        returns_df=load_source(sourcefile)\n",
    "    else:\n",
    "        print('UNABLE TO DETERMINE SOURCE TYPE')\n",
    "        raise\n",
    "    print(returns_df.head())\n",
    "    \n",
    "    #log leveraged surplus optimizations\n",
    "    big_exputil_df=pd.DataFrame(np.zeros((1,len(Llist))),columns=Llist)\n",
    "    big_walloc=np.zeros((len(returns_df.columns),len(Llist)))\n",
    "    big_walloc_df = pd.DataFrame(big_walloc,columns=Llist,index=returns_df.columns)\n",
    "    big_implied_dif = np.zeros((len(returns_df.columns),len(Llist)))\n",
    "    big_implied_dif_df = pd.DataFrame(big_implied_dif,columns=Llist,index=returns_df.columns)\n",
    "    for lev in Llist:\n",
    "        (error_code1, wpreturns,walloc,exputil) = find_best_allocation(returns_df,lev,long_only,worst)\n",
    "        big_walloc_df[lev]=walloc\n",
    "        big_exputil_df[lev]=exputil\n",
    "        big_implied_dif_df[lev] = find_implied_dif_expected_returns(returns_df,lev,worst,walloc,exputil,use_conic)\n",
    "         \n",
    "    with pd.option_context('display.float_format', '{:,.5f}'.format):\n",
    "        print(' ')\n",
    "        print('OPTIMAL ALLOCATIONS')\n",
    "        print(big_walloc_df)\n",
    "        print(' ')\n",
    "        print('EXPECTED UTILITIES')\n",
    "        print(big_exputil_df)\n",
    "        print(' ')\n",
    "        print('IMPLIED DIFFERENCE IN EXPECTED RETURN (CONIC SOLVER)' if use_conic else 'IMPLIED DIFFERENCE IN EXPECTED RETURN (NELDER-MEAD)')\n",
    "        print(big_implied_dif_df)\n",
    "    print(' ')        \n",
    "    \n",
    "    print('DONE!')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET PARAMETERS AND RUN OPTIMIZATION WITH CONIC SOLVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "params=dict(\n",
    "    sourcefile='DATA20/prices.csv',\n",
    "    sourcetype='PRICES',\n",
    "    Llist=[1,2,4,8],\n",
    "    long_only=True,\n",
    "    worst=(-0.99),\n",
    "    actual_alloc=None,\n",
    "    expected_returns=None,\n",
    "    use_conic=True  # Use conic solver\n",
    "    )\n",
    "\n",
    "#run main program with conic solver\n",
    "print(\"Running with CONIC SOLVER:\")\n",
    "print(\"=\"*50)\n",
    "optimizer_output=woptimize(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE WITH NELDER-MEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run with Nelder-Mead for comparison\n",
    "params['use_conic'] = False\n",
    "print(\"\\nRunning with NELDER-MEAD for comparison:\")\n",
    "print(\"=\"*50)\n",
    "optimizer_output_nm=woptimize(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}