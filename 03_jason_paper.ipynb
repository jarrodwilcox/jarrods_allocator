{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import fmin_slsqp as slsqp\n",
    "from datetime import datetime\n",
    "from math import exp, isnan\n",
    "try:\n",
    "    import cvxpy as cp    \n",
    "except:\n",
    "    print ('This version of higher_moments requires installation of cvxpy.')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET ASSET GROUP CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get asset group codes\n",
    "def load_asset_codes(codefile=None):\n",
    "    try:\n",
    "        equivs=pd.read_csv(codefile).values\n",
    "        equivs=[x if isinstance(x[1],str) else [x[0],'NOGROUP'] for x in equivs]\n",
    "        lookup_group={}\n",
    "        for tick in equivs:\n",
    "            lookup_group[tick[0]]=tick[1]\n",
    "        members={}\n",
    "        categories=sorted(set([x[1] for x in equivs]))\n",
    "        for group in categories:\n",
    "            members[group]=[x[0] for x in equivs if x[1]==group]     \n",
    "        return(lookup_group,members)\n",
    "    except:\n",
    "        print('NO ASSET CATEGORIZATION FOUND')\n",
    "        raise\n",
    "\n",
    "#a,b=load_asset_codes('CDATA40/equiv.csv')\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD INPUT PRICE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(sourcefile):\n",
    "    try:\n",
    "        source=pd.read_csv(sourcefile)\n",
    "        temp=source.get('Date')\n",
    "        if not temp is None:\n",
    "            source.index=temp \n",
    "            source=source.drop(columns=['Date'])\n",
    "        return source\n",
    "    except:\n",
    "        print('NO SOURCE FOUND')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REARRANGE COLUMNS BY ASSET CLASS IF SOURCE IS RETURN FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rearrange(members,source):\n",
    "    cols=[tick for group in members for tick in members[group]]\n",
    "    source2=pd.DataFrame(columns=cols,index=source.index)\n",
    "    for tick in cols:\n",
    "        source2[tick]=source[tick]\n",
    "    return(source2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATE RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(prices2,return_interval):\n",
    "    price_data=np.array(prices2.values,dtype='float32')\n",
    "    price_data1=np.ones((price_data.shape[0],price_data.shape[1]))\n",
    "    price_data1[return_interval:]=price_data[:-return_interval]\n",
    "    returns=(price_data/price_data1)\n",
    "    returns=returns[return_interval:]-1. \n",
    "    returns_df=pd.DataFrame(returns)   \n",
    "    returns_df.columns=prices2.columns\n",
    "    returns_df.index=prices2.index[return_interval:]\n",
    "    return(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLLECT FURTHER STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rtn_summary(returns,tickers):\n",
    "    means=np.mean(returns,axis=0) \n",
    "    covs=np.cov(returns.T)\n",
    "    stdevs=np.std(returns,axis=0)\n",
    "    corrs=np.round(np.corrcoef(returns.T),2)\n",
    "    corr=pd.DataFrame(corrs,columns=tickers)\n",
    "    means=pd.Series(means)\n",
    "    stdev=pd.Series(stdevs)\n",
    "    skews=stats.skew(returns,axis=0)\n",
    "    skew=pd.Series(skews)\n",
    "    kurts=stats.kurtosis(returns,axis=0,fisher=False)\n",
    "    kurt=pd.Series(kurts)\n",
    "    descript=pd.DataFrame({'TICKER':tickers,'MEAN':np.round(means,4),\n",
    "        'STDEV':np.round(stdev,4),'SKEW':np.round(skew,2),'KURT':np.round(kurt,2)})\n",
    "    combined=descript.join(corr,how='outer')      \n",
    "        \n",
    "    return (means,covs,skews,kurts,combined)\n",
    "#means,covs,skews,kurts=rtn_summary(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLSQP HILL-CLIMBING OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_init_allocate(returns_df):\n",
    "    ncols=len(returns_df.columns)\n",
    "    def_init_alloc=np.zeros(ncols,dtype='float64')\n",
    "    stdevs=np.std(returns_df,axis=0)\n",
    "    mn=np.min(stdevs)\n",
    "    idx=[i for i,v in enumerate(stdevs) if v==mn][0]\n",
    "    def_init_alloc[idx]=1.0        \n",
    "    return def_init_alloc\n",
    "\n",
    "def eqcons1(x,*args): #budget constraint\n",
    "    return(np.array([np.sum(x)-1.0]))\n",
    "\n",
    "def mobjective(x,means,covariance,risk_aversion):\n",
    "    mn=np.dot(x,means)\n",
    "    cv=np.matmul(x.T,covariance)\n",
    "    cv2=np.dot(cv,x)\n",
    "    return(-mn+risk_aversion*cv2/2.0)\n",
    "\n",
    "def wobjective2(x,levreturns,worst,leverage):\n",
    "    levportreturn=np.matmul(levreturns,x)\n",
    "    squeeze=(1.0+worst)/leverage  #for compressing over 100% losses to nearly 100%    \n",
    "    new_worst=worst+(levportreturn+1.0)*squeeze #compressing\n",
    "    safeportreturn=np.maximum(levportreturn,new_worst)     \n",
    "    log_portreturn=np.log1p(safeportreturn) #log(1+X) numpy function\n",
    "    return (-np.sum(log_portreturn))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "def hill_climb(returns,levs,means,covs,headers,labels,long_only,worst,ob,alloc_mat=None):\n",
    "    merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    ncols2=returns.shape[1]\n",
    "    nrows2=returns.shape[0]\n",
    "    nlevs=len(levs)   \n",
    "    alloc=np.ones((nlevs,ncols2),dtype='float64')\n",
    "    prtns=np.zeros((nlevs,nrows2),dtype='float64')\n",
    "    returns_df=pd.DataFrame(returns)\n",
    "    def_init_alloc=default_init_allocate(returns_df)\n",
    "    if not long_only:\n",
    "        print('Not set up for long-short problems')\n",
    "        raise\n",
    "    #long-only bounds\n",
    "    upper=np.ones(ncols2,dtype='float64')\n",
    "    lower=np.zeros(ncols2,dtype='float64')\n",
    "    bounds=list(zip(lower,upper))\n",
    "   \n",
    "    for i in range(nlevs):     #in this use where called by cvxpy call, keep iteration over single leverage  \n",
    "        lev=levs[i]\n",
    "        levreturn=returns*lev\n",
    "        \n",
    "        if alloc_mat is None:\n",
    "            x0=default_init_allocate(returns_df)\n",
    "        else:\n",
    "            x0=alloc_mat[i]\n",
    "            \n",
    "        if ob=='MV':\n",
    "            # run mean_variance optimizer                                   \n",
    "            temp=slsqp(mobjective,x0,eqcons=[eqcons1],args=tuple((means,covs,lev)),bounds=bounds,full_output=True,acc=1e-07) \n",
    "            alloc[i]=temp[0]\n",
    "        \n",
    "        if ob=='LLS':\n",
    "            # run LLS optimizer\n",
    "            levreturns=returns*lev      \n",
    "            temp=slsqp(wobjective2,x0,eqcons=[eqcons1],args=tuple((levreturns,worst,lev)),bounds=bounds,full_output=True,acc=1e-08)\n",
    "            alloc[i]=temp[0]\n",
    "    return (None,alloc[::],None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVXPY OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_with_cvxpy2(orig_rtns,mrtns,levs,mmeans,mcovs,headers,labels,long_only,worst,ob):\n",
    "    barrier=worst+1\n",
    "    merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    nrows,ncols=mrtns.shape\n",
    "    nlevs=len(levs)\n",
    "    mns=mmeans.values\n",
    "    orig_means=np.mean(orig_rtns,axis=0)\n",
    "    orig_covs=np.cov(orig_rtns.T)\n",
    "    alloc=np.ones((nlevs,ncols),dtype='float64')\n",
    "    prtns=np.zeros((nlevs,nrows),dtype='float64')\n",
    "    \n",
    "    xx=cp.Variable(ncols)\n",
    "    for i in range(nlevs):\n",
    "        lev=levs[i]\n",
    "        mlevreturn=(mrtns*lev)\n",
    "        orig_levreturn=(orig_rtns*lev)\n",
    "        #print(' ')       \n",
    "        print(\"Risk Aversion: \",lev)\n",
    "        if ob=='MV':\n",
    "            if long_only:\n",
    "                constraints =[sum(xx)==1, 0<=xx, xx<=1] #Long-only portfolios\n",
    "            else:\n",
    "                constraints = [sum(xx)==1.0] \n",
    "            objective=cp.Minimize(-cp.sum(cp.multiply(mns,xx)) + lev*cp.quad_form(xx,mcovs)/2.0)\n",
    "            prob=cp.Problem(objective,constraints)\n",
    "            result=prob.solve(solver=cp.CLARABEL,tol_feas=1e-8,tol_gap_abs=1e-8, tol_gap_rel=1e-8, tol_ktratio=1e-8, verbose=False)\n",
    "            xxvalue=xx.value\n",
    "            prtns[i]=np.dot(orig_rtns,xxvalue)\n",
    "            \n",
    "            merit.loc[headers[i],'M_objective'] = np.sum(orig_means*xxvalue) - levs[i]*np.dot(np.dot(xxvalue,orig_covs),xxvalue.T)/2.0\n",
    "            merit.loc[headers[i],'W_objective'] = (np.sum(np.log1p(lev*np.dot(orig_rtns,xxvalue.T)))/nrows)/lev\n",
    "            \n",
    "        elif ob=='LLS':\n",
    "            if long_only:\n",
    "                constraints =[sum(xx)==1, 0<=xx, xx<=1, -1.0+barrier <= mlevreturn @ xx ] #Long-only portfolios\n",
    "            else:\n",
    "                constraints = [sum(xx)==1,-1.0+barrier <= mlevreturn @ xx ]\n",
    "            objective=cp.Minimize(cp.sum(-cp.log1p(mlevreturn@xx)))\n",
    "            prob=cp.Problem(objective,constraints)\n",
    "            result=prob.solve(solver=cp.CLARABEL,tol_feas=1e-8,tol_gap_abs=1e-8, tol_gap_rel=1e-8, tol_ktratio=1e-8, verbose=False) /nrows\n",
    "            xxvalue=xx.value\n",
    "            if xxvalue is None:                \n",
    "                print('WARNING!!!! cvxpy problem may not be feasible.')\n",
    "                print('Using sqslp with catastrophic returns converted to less extreme losses.')\n",
    "                dummy1,wallocz,dummy2=hill_climb(mrtns,[lev],mmeans,mcovs,headers,labels,long_only,worst,ob,alloc_mat=None)\n",
    "                xxvalue=wallocz[0]\n",
    "                \n",
    "            prtns[i]=np.dot(orig_rtns,xxvalue)\n",
    "            merit.loc[headers[i],'M_objective']= sum(orig_means*xxvalue) - levs[i]*np.dot(np.dot(xxvalue,orig_covs),xxvalue.T)/2.0\n",
    "            merit.loc[headers[i],'W_objective']= (np.sum(np.log1p(np.dot(orig_levreturn,xxvalue)))/nrows)/lev        \n",
    "        alloc[i]=xxvalue        \n",
    "    \n",
    "    return (prtns[::].T,alloc[::],pd.DataFrame.copy(merit,deep=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALL ALTERNATIVE ALLOCATION OPTIMIZERS AND DESCRIBE OBJECTIVE RESULTS AND DIVERSIFICATION IN-SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_allocation(rtns_df,mrtns_df,long_only,worst,levs,lookup_group=None):\n",
    "    rtns=rtns_df.values\n",
    "    mrtns=mrtns_df.values\n",
    "    rtns_cols=rtns_df.columns\n",
    "    means=np.mean(rtns_df,axis=0)\n",
    "    mmeans=np.mean(mrtns_df,axis=0)\n",
    "    covs=np.cov(rtns_df.T)\n",
    "    mcovs=np.cov(mrtns_df.T)\n",
    "    headers=['L:'+x for x in list(map(str,levs))]\n",
    "    labels=['W_objective','M_objective']\n",
    "    \n",
    "    print('RUNNING MEAN-VARIANCE OPTIMIZATION')\n",
    "    mpreturns,malloc,M_merit=optim_with_cvxpy2(rtns,mrtns,levs,mmeans,mcovs,headers,labels,long_only,worst,ob=\"MV\")\n",
    "    print(' ')\n",
    "    print('RUNNING EXPECTED SURPLUS GROWTH OPTIMIZATION')\n",
    "    wpreturns,walloc,W_merit=optim_with_cvxpy2(rtns,mrtns,levs,mmeans,mcovs,headers,labels,long_only,worst,ob=\"LLS\")\n",
    "    \n",
    "    print(' ')\n",
    "    print('ALLOCATIONS TO MAXIMIZE MEAN-VARIANCE')  \n",
    "    print(pd.DataFrame(np.round(malloc,5),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    print('ALLOCATIONS TO MAXIMIZE EXPECTED SURPLUS GROWTH')\n",
    "    print(pd.DataFrame(np.round(walloc,5),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    print('INCREMENTAL ALLOCATIONS')\n",
    "    dalloc=np.subtract(walloc,malloc)\n",
    "    print(pd.DataFrame(np.round(dalloc,4),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    print('IN-SAMPLE ALLOCATION MERIT FROM MEAN-VARIANCE')\n",
    "    print(M_merit[['W_objective','M_objective']].head(10))\n",
    "    print(' ')    \n",
    "    print('IN-SAMPLE ALLOCATION MERIT FROM EXPECTED SURPLUS GROWTH')\n",
    "    print(W_merit[['W_objective','M_objective']].head(10))\n",
    "    print(' ')\n",
    "    print('INCREMENTAL MERIT')\n",
    "    delta_merit=np.subtract(np.array(W_merit),np.array(M_merit))\n",
    "    D_merit=pd.DataFrame(delta_merit,columns=W_merit.columns, index=W_merit.index)\n",
    "    #following necessary because np.round fails on NaN\n",
    "    with pd.option_context('display.float_format', '{:,.5f}'.format):\n",
    "        print(D_merit)\n",
    "    \n",
    "    return (wpreturns,mpreturns,walloc,malloc,W_merit,M_merit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTEND ALLOCATION CONSEQUENCES TO PORTFOLIO RETURN CHARACTERISTICS IN SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_xray(merit,objective,levs,pmean,pstd,pskew,pkurt):\n",
    "    #X-ray on optimal in-sample surplus log growth rate objective\n",
    "    exp_utility=[x for x in merit[objective].values]\n",
    "    xray=pd.DataFrame([levs,exp_utility,pmean,pstd,pskew,pkurt]).T\n",
    "    xray.columns=['Leverage','Exp_Log_Gr','mean','stdev','skewness','kurtosis']\n",
    "    \n",
    "    xray['Q'] = xray['Leverage']*xray['stdev']/(1+xray['Leverage']*xray['mean'])\n",
    "    print(' ')\n",
    "    headers=['L:'+x for x in list(map(str,levs))]\n",
    "    Q_df=pd.DataFrame([headers,xray['Q']]).T\n",
    "    Q_df.columns=['Leverage','Q']\n",
    "    with pd.option_context('display.float_format', '{:,.3f}'.format):\n",
    "        print(Q_df.to_string(index=False))\n",
    "    \n",
    "    xray['First']= np.log1p(xray['Leverage']*xray['mean'])\n",
    "    xray['Second']=-(xray['Q']**2)/2\n",
    "    xray['Third']=xray['skewness']*(xray['Q']**3)/3\n",
    "    xray['Fourth']=-xray['kurtosis']*(xray['Q']**4)/4\n",
    "    xray['Residual']=xray['Exp_Log_Gr']-xray['First']-xray['Second']-xray['Third']-xray['Fourth']\n",
    "    xray=xray.drop(['mean','stdev','skewness','kurtosis','Q'],axis=1)\n",
    "    print(' ')\n",
    "    \n",
    "    print('COMPOSITION BY RETURN DISTRIBUTION MOMENTS:')\n",
    "    print(' ')\n",
    "    print(xray.to_string(index=False))    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_portfolio_returns(wprtns,mprtns,wmerit,mmerit,levs):\n",
    "    #COMPARE OUTPUTS ON TRADITIONAL STATISTICS\n",
    "    print(' ')\n",
    "    \n",
    "    wpmean=pd.Series(np.mean(wprtns,axis=0))\n",
    "    wpstd=pd.Series(np.std(wprtns,axis=0))\n",
    "    wpskew=pd.Series(stats.skew(wprtns,axis=0))\n",
    "    wpkurt=pd.Series(stats.kurtosis(wprtns,axis=0,fisher=False))    \n",
    "\n",
    "    mpmean=pd.Series(np.mean(mprtns,axis=0))\n",
    "    mpstd=pd.Series(np.std(mprtns,axis=0))\n",
    "    mpskew=pd.Series(stats.skew(mprtns,axis=0))\n",
    "    mpkurt=pd.Series(stats.kurtosis(mprtns,axis=0,fisher=False))\n",
    "    \n",
    "    pdescribe1=pd.DataFrame({'WMEAN': np.round(wpmean,4),'MMEAN':np.round(mpmean,4)})\n",
    "    pdescribe2=pd.DataFrame({'WSTD': np.round(wpstd,4),'MSTD':np.round(mpstd,4)})\n",
    "    pdescribe3=pd.DataFrame({'WSKEW': np.round(wpskew,3),'MSKEW':np.round(mpskew,3)})\n",
    "    pdescribe4=pd.DataFrame({'WKURT': np.round(wpkurt,3),'MKURT':np.round(mpkurt,3)})   \n",
    "    pdescribe=pd.concat([pdescribe1,pdescribe2,pdescribe3,pdescribe4],axis=1,sort=False)\n",
    "    pdescribe.index=['L:'+x for x in list(map(str,levs))]\n",
    "    print('COMPARE PORTFOLIO STATISTICS')\n",
    "\n",
    "    print(' ')\n",
    "    print('IN_SAMPLE SURPLUS GROWTH OBJECTIVE WITH MEAN-VARIANCE OPTIMIZATION')\n",
    "    show_xray(mmerit,'W_objective',levs,mpmean,mpstd,mpskew,mpkurt)\n",
    "    print(' ')\n",
    "    print('IN-SAMPLE SURPLUS GROWTH OBJECTIVE WITH SURPLUS GROWTH OPTIMIZATION')\n",
    "    show_xray(wmerit,'W_objective',levs,wpmean,wpstd,wpskew,wpkurt)\n",
    "    print(' ')\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESEARCH RECORDKEEPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters(journalfile,logfile,sample,codefile,sourcefile,sourcetype,Llist,long_only,return_interval,worst):\n",
    "    print(' ')    \n",
    "    print(f'{journalfile=}')\n",
    "    print(f'{logfile=}')\n",
    "    print(f'{sample=}')\n",
    "    print(f'{codefile=}')\n",
    "    print(f'{sourcefile=}')\n",
    "    print(f'{sourcetype=}')\n",
    "    print(f'{Llist=}')\n",
    "    print(f'{long_only=}') \n",
    "    print(f'{return_interval=}')\n",
    "    print(f'{worst=}')\n",
    "    print(' ')\n",
    "    return\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_moments(params={}):\n",
    "\n",
    "    journalfile=params.get('journalfile')\n",
    "    logfile=params.get('logfile')\n",
    "    sample=params.get('sample')\n",
    "    codefile=params.get('codefile')\n",
    "    sourcefile=params.get('sourcefile')\n",
    "    sourcetype=params.get('sourcetype')    \n",
    "    Llist=params.get('Llist')\n",
    "    long_only=params.get('long_only')\n",
    "    return_interval=params.get('return_interval')\n",
    "    worst=params.get('worst')\n",
    "   \n",
    "    #See import dependencies in first cell\n",
    "\n",
    "    #record run description in journalfile\n",
    "    orig_stdout = sys.stdout\n",
    "    e=open(journalfile, 'a')\n",
    "    sys.stdout=e\n",
    "    print_parameters(journalfile,logfile,sample,codefile,sourcefile,sourcetype,Llist,long_only,return_interval,worst)\n",
    "    e.close()\n",
    "\n",
    "    #record results in logfile\n",
    "    f = open(logfile, 'w')\n",
    "    sys.stdout = f\n",
    "\n",
    "    #record control parameters\n",
    "    print_parameters(journalfile,logfile,sample,codefile,sourcefile,sourcetype,Llist,long_only,return_interval,worst)\n",
    "\n",
    "    #Read in asset categories and members\n",
    "    try:\n",
    "        lookup_group,members=load_asset_codes(codefile)\n",
    "        print(' ')\n",
    "        print('Asset groups and members:')\n",
    "        print(members)\n",
    "        print(' ')\n",
    "    except:\n",
    "        print('Error: Failed to load codefile')\n",
    "        raise\n",
    "        \n",
    "    #Read in Prices or Returns, based on sourcetype, adjusted for dividends and interest if possible\n",
    "    \n",
    "    if sourcetype=='PRICES':\n",
    "        #prices=load_source(sourcefile) \n",
    "        #Rearrange prices by asset class for greater interpretability\n",
    "        prices2=rearrange(members,load_source(sourcefile) )\n",
    "        #Calculate return matrix\n",
    "        returns_df=calculate_returns(prices2,return_interval)\n",
    "    elif sourcetype=='RETURNS':\n",
    "        returns_df=rearrange(members,load_source(sourcefile))\n",
    "    else:\n",
    "        print('UNABLE TO DETERMINE SOURCE TYPE')\n",
    "        raise\n",
    "        \n",
    "    # optionally...\n",
    "    print(' ')\n",
    "    print('RETURNS SAMPLE')\n",
    "    print(returns_df.head())\n",
    "    print(' ')\n",
    "    print(returns_df.tail())\n",
    "    print(' ')\n",
    "\n",
    "    print('RETURNS DESCRIPTION')\n",
    "    print(returns_df.describe())\n",
    "    \n",
    "    # Do mean-variance and log leveraged surplus optimizations\n",
    "    (wpreturns,mpreturns,walloc,malloc,\n",
    "        W_merit,M_merit) = find_best_allocation(returns_df,\n",
    "        returns_df,long_only,worst,Llist,lookup_group)\n",
    "\n",
    "    #describe portfolio return statistics for different leverages\n",
    "    describe_portfolio_returns(wpreturns,mpreturns,W_merit, M_merit,Llist)\n",
    "\n",
    "    #close logfile and print it on terminal\n",
    "    f.close()\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "    h=open(logfile,'r')\n",
    "    for line in h:\n",
    "        if len(line)>0:          \n",
    "            print(line[:-1])          \n",
    "    h.close()\n",
    "        \n",
    "    optimizer_output={\n",
    "        \"params\":params,\n",
    "        \"members\":members,\n",
    "        \"returns_df\":returns_df,\n",
    "        \"wpreturns\":wpreturns,\n",
    "        \"mpreturns\":mpreturns,\n",
    "        \"walloc\":walloc,\n",
    "        \"malloc\":malloc,\n",
    "        \"W_merit\":W_merit,\n",
    "        \"M_merit\": M_merit,\n",
    "    }\n",
    "\n",
    "    \n",
    "    print(' ')\n",
    "    print('DONE!')\n",
    "    \n",
    "    return optimizer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET PARAMETERS AND CALL RESEARCH OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "journalfile='JOURNAL.txt'\n",
      "logfile='RUNxx.txt'\n",
      "sample='20YR'\n",
      "codefile='CDATA20/equiv.csv'\n",
      "sourcefile='CDATA20/prices.csv'\n",
      "sourcetype='PRICES'\n",
      "Llist=[1, 2]\n",
      "long_only=True\n",
      "return_interval=1\n",
      "worst=-0.99\n",
      " \n",
      " \n",
      "Asset groups and members:\n",
      "{'BOND': ['VFIIX', 'VUSTX', 'VWESX', 'VFITX'], 'CASH': ['VWSTX'], 'JUNK': ['VWEHX', 'VWAHX'], 'STOCK': ['XLE', 'EWJ', 'XLP', 'XLV', 'XLY', 'DIA', 'XLK', 'SPY']}\n",
      " \n",
      " \n",
      "RETURNS SAMPLE\n",
      "               VFIIX     VUSTX     VWESX     VFITX     VWSTX     VWEHX  \\\n",
      "Date                                                                     \n",
      "1999-01-01  0.008281  0.009904  0.028578  0.006580  0.004880  0.019328   \n",
      "1999-02-01 -0.007106 -0.047315 -0.036633 -0.030332  0.001924 -0.005854   \n",
      "1999-03-01  0.006325 -0.015088 -0.005120  0.005414  0.000833  0.007603   \n",
      "1999-04-01  0.004371  0.013424  0.004758  0.003062  0.002508  0.013409   \n",
      "1999-05-01 -0.008280 -0.017152 -0.016449 -0.013952  0.001801 -0.016409   \n",
      "\n",
      "               VWAHX       XLE       EWJ       XLP       XLV       XLY  \\\n",
      "Date                                                                     \n",
      "1999-01-01  0.018370 -0.065596  0.025385 -0.013233  0.048077  0.051435   \n",
      "1999-02-01 -0.002812 -0.008597 -0.035715 -0.010496  0.001147 -0.006257   \n",
      "1999-03-01 -0.000547  0.137284  0.135803 -0.002947  0.026346  0.047510   \n",
      "1999-04-01  0.004415  0.152157  0.043478 -0.033165  0.035714  0.027344   \n",
      "1999-05-01 -0.006809 -0.021583 -0.057292 -0.010410 -0.030712 -0.045261   \n",
      "\n",
      "                 DIA       XLK       SPY  \n",
      "Date                                      \n",
      "1999-01-01  0.020846  0.159004  0.038665  \n",
      "1999-02-01 -0.002542 -0.099173 -0.032069  \n",
      "1999-03-01  0.054013  0.074312  0.038948  \n",
      "1999-04-01  0.102672  0.005978  0.040492  \n",
      "1999-05-01 -0.022916  0.003396 -0.022866  \n",
      " \n",
      "               VFIIX     VUSTX     VWESX     VFITX     VWSTX     VWEHX  \\\n",
      "Date                                                                     \n",
      "2019-09-01  0.000288 -0.026225 -0.019730 -0.006933 -0.000569  0.004441   \n",
      "2019-10-01  0.003036 -0.011064  0.001166  0.001750  0.001897  0.005968   \n",
      "2019-11-01  0.001142 -0.003858  0.003874 -0.003576  0.001328  0.006129   \n",
      "2019-12-01  0.000097 -0.032736 -0.021278 -0.003690  0.001770  0.012744   \n",
      "2020-01-01  0.003040  0.023923  0.027542  0.006886  0.001895  0.006059   \n",
      "\n",
      "               VWAHX       XLE       EWJ       XLP       XLV       XLY  \\\n",
      "Date                                                                     \n",
      "2019-09-01 -0.006489  0.029923  0.052300  0.011528 -0.005188  0.009366   \n",
      "2019-10-01  0.000085 -0.011992  0.034191  0.001658  0.055626  0.004564   \n",
      "2019-11-01  0.002738  0.016046  0.012781  0.013734  0.050026  0.013239   \n",
      "2019-12-01  0.000938  0.019528 -0.003197  0.015806  0.023821  0.024255   \n",
      "2020-01-01  0.010179  0.054330  0.014834  0.000668  0.010776  0.009377   \n",
      "\n",
      "                 DIA       XLK       SPY  \n",
      "Date                                      \n",
      "2019-09-01  0.021806  0.012574  0.014772  \n",
      "2019-10-01  0.007231  0.042229  0.026825  \n",
      "2019-11-01  0.039374  0.053663  0.036198  \n",
      "2019-12-01  0.016649  0.039814  0.024021  \n",
      "2020-01-01  0.009668  0.013003  0.010474  \n",
      " \n",
      "RETURNS DESCRIPTION\n",
      "            VFIIX       VUSTX       VWESX       VFITX       VWSTX       VWEHX  \\\n",
      "count  253.000000  253.000000  253.000000  253.000000  253.000000  253.000000   \n",
      "mean     0.003782    0.005668    0.006024    0.003844    0.001749    0.005004   \n",
      "std      0.008570    0.031257    0.025899    0.014504    0.002296    0.021435   \n",
      "min     -0.030771   -0.086092   -0.093105   -0.060327   -0.005859   -0.155371   \n",
      "25%     -0.000761   -0.014780   -0.008842   -0.004197    0.000443   -0.004722   \n",
      "50%      0.003780    0.006419    0.005747    0.004120    0.001801    0.006744   \n",
      "75%      0.008713    0.020183    0.021228    0.011398    0.002963    0.015159   \n",
      "max      0.038096    0.121016    0.131348    0.056121    0.011195    0.085158   \n",
      "\n",
      "            VWAHX         XLE         EWJ         XLP         XLV         XLY  \\\n",
      "count  253.000000  253.000000  253.000000  253.000000  253.000000  253.000000   \n",
      "mean     0.004156    0.007496    0.003875    0.005799    0.007405    0.008575   \n",
      "std      0.013331    0.062078    0.048624    0.034917    0.040094    0.051566   \n",
      "min     -0.051652   -0.185375   -0.155722   -0.120137   -0.145144   -0.173442   \n",
      "25%     -0.003124   -0.027826   -0.027541   -0.010496   -0.015983   -0.016720   \n",
      "50%      0.005634    0.010103    0.005270    0.008244    0.010931    0.008973   \n",
      "75%      0.011618    0.046228    0.035281    0.029086    0.031250    0.041911   \n",
      "max      0.051849    0.196099    0.135803    0.093821    0.116004    0.191629   \n",
      "\n",
      "              DIA         XLK         SPY  \n",
      "count  253.000000  253.000000  253.000000  \n",
      "mean     0.007198    0.007327    0.006252  \n",
      "std      0.040436    0.066357    0.041981  \n",
      "min     -0.134507   -0.249061   -0.160355  \n",
      "25%     -0.014857   -0.025705   -0.016480  \n",
      "50%      0.009668    0.012574    0.010921  \n",
      "75%      0.030414    0.043940    0.031195  \n",
      "max      0.104567    0.247675    0.114886  \n",
      "RUNNING MEAN-VARIANCE OPTIMIZATION\n",
      "Risk Aversion:  1\n",
      "Risk Aversion:  2\n",
      " \n",
      "RUNNING EXPECTED SURPLUS GROWTH OPTIMIZATION\n",
      "Risk Aversion:  1\n",
      "Risk Aversion:  2\n",
      " \n",
      "ALLOCATIONS TO MAXIMIZE MEAN-VARIANCE\n",
      "           L:1      L:2\n",
      "VFIIX  0.00000  0.00000\n",
      "VUSTX  0.02092  0.30883\n",
      "VWESX  0.00000  0.00000\n",
      "VFITX  0.00000  0.00000\n",
      "VWSTX  0.00000  0.00000\n",
      "VWEHX  0.00000  0.00000\n",
      "VWAHX  0.00000  0.00000\n",
      "XLE    0.00573  0.05885\n",
      "EWJ    0.00000  0.00000\n",
      "XLP    0.00000  0.00000\n",
      "XLV    0.02020  0.11912\n",
      "XLY    0.95315  0.51321\n",
      "DIA    0.00000  0.00000\n",
      "XLK    0.00000  0.00000\n",
      "SPY    0.00000  0.00000\n",
      " \n",
      "ALLOCATIONS TO MAXIMIZE EXPECTED SURPLUS GROWTH\n",
      "           L:1      L:2\n",
      "VFIIX  0.00000  0.00000\n",
      "VUSTX  0.02917  0.31558\n",
      "VWESX  0.00000  0.00000\n",
      "VFITX  0.00000  0.00000\n",
      "VWSTX  0.00000  0.00000\n",
      "VWEHX  0.00000  0.00000\n",
      "VWAHX  0.00000  0.00000\n",
      "XLE    0.00000  0.05302\n",
      "EWJ    0.00000  0.00000\n",
      "XLP    0.00000  0.00000\n",
      "XLV    0.00512  0.10951\n",
      "XLY    0.96571  0.52188\n",
      "DIA    0.00000  0.00000\n",
      "XLK    0.00000  0.00000\n",
      "SPY    0.00000  0.00000\n",
      " \n",
      "INCREMENTAL ALLOCATIONS\n",
      "          L:1     L:2\n",
      "VFIIX -0.0000 -0.0000\n",
      "VUSTX  0.0082  0.0068\n",
      "VWESX -0.0000 -0.0000\n",
      "VFITX -0.0000 -0.0000\n",
      "VWSTX -0.0000 -0.0000\n",
      "VWEHX -0.0000 -0.0000\n",
      "VWAHX -0.0000 -0.0000\n",
      "XLE   -0.0057 -0.0058\n",
      "EWJ   -0.0000 -0.0000\n",
      "XLP   -0.0000 -0.0000\n",
      "XLV   -0.0151 -0.0096\n",
      "XLY    0.0126  0.0087\n",
      "DIA   -0.0000 -0.0000\n",
      "XLK   -0.0000 -0.0000\n",
      "SPY   -0.0000 -0.0000\n",
      " \n",
      "IN-SAMPLE ALLOCATION MERIT FROM MEAN-VARIANCE\n",
      "    W_objective M_objective\n",
      "L:1    0.007224    0.007248\n",
      "L:2     0.00647    0.006516\n",
      " \n",
      "IN-SAMPLE ALLOCATION MERIT FROM EXPECTED SURPLUS GROWTH\n",
      "    W_objective M_objective\n",
      "L:1    0.007224    0.007247\n",
      "L:2     0.00647    0.006516\n",
      " \n",
      "INCREMENTAL MERIT\n",
      "    W_objective M_objective\n",
      "L:1     0.00000    -0.00000\n",
      "L:2     0.00000    -0.00000\n",
      " \n",
      "COMPARE PORTFOLIO STATISTICS\n",
      " \n",
      "IN_SAMPLE SURPLUS GROWTH OBJECTIVE WITH MEAN-VARIANCE OPTIMIZATION\n",
      " \n",
      "Leverage     Q\n",
      "     L:1 0.049\n",
      "     L:2 0.061\n",
      " \n",
      "COMPOSITION BY RETURN DISTRIBUTION MOMENTS:\n",
      " \n",
      " Leverage  Exp_Log_Gr    First    Second     Third    Fourth      Residual\n",
      "      1.0    0.007224 0.008449 -0.001211 -0.000007 -0.000006 -1.462830e-07\n",
      "      2.0    0.006470 0.014838 -0.001853 -0.000028 -0.000015 -6.471302e-03\n",
      " \n",
      "IN-SAMPLE SURPLUS GROWTH OBJECTIVE WITH SURPLUS GROWTH OPTIMIZATION\n",
      " \n",
      "Leverage     Q\n",
      "     L:1 0.049\n",
      "     L:2 0.061\n",
      " \n",
      "COMPOSITION BY RETURN DISTRIBUTION MOMENTS:\n",
      " \n",
      " Leverage  Exp_Log_Gr    First    Second     Third    Fourth      Residual\n",
      "      1.0    0.007224 0.008448 -0.001211 -0.000007 -0.000006 -1.387079e-07\n",
      "      2.0    0.006470 0.014834 -0.001850 -0.000027 -0.000015 -6.471539e-03\n",
      " \n",
      " \n",
      "DONE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarrodwilcox/pydev13/venv/lib/python3.13/site-packages/cvxpy/problems/problem.py:1510: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#set parameters\n",
    "\n",
    "params=dict(\n",
    "    journalfile='JOURNAL.txt',\n",
    "    logfile='RUNxx.txt',\n",
    "    sample='20YR',\n",
    "    codefile='CDATA20/equiv.csv',\n",
    "    sourcefile='CDATA20/prices.csv',\n",
    "    sourcetype='PRICES',\n",
    "    Llist=[1,2],\n",
    "    long_only=True,\n",
    "    return_interval=1,\n",
    "    worst=(-0.99),\n",
    "    )\n",
    "#run main program\n",
    "optimizer_output=higher_moments(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
